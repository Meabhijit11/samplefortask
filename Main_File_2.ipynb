{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd029ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error - Linear Regression: 36.47475102148569\n",
      "Mean Squared Error - XGBoost: 20.600286109514986\n",
      "Mean Squared Error - ARIMA: 511.47982120952094\n",
      "Mean Squared Error - Deep Neural Network: 21.631000567806247\n",
      "Mean Squared Error - Random Forest: 20.597555570732894\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load the dataset\n",
    "# Assuming 'data.csv' is the name of your dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Feature engineering\n",
    "df['start_datetime'] = pd.to_datetime(df['start_date'] + ' ' + df['start_time_hour'].astype(str) + ':' + df['start_time_minute'].astype(str))\n",
    "df['end_datetime'] = pd.to_datetime(df['end_date'] + ' ' + df['end_time_hour'].astype(str) + ':' + df['end_time_minute'].astype(str))\n",
    "df['trip_duration_minutes'] = (df['end_datetime'] - df['start_datetime']).dt.total_seconds() / 60.0\n",
    "\n",
    "# Aggregating demand by time\n",
    "demand_data = df.groupby('start_datetime')['tripDistance'].count().reset_index()\n",
    "demand_data.columns = ['timestamp', 'demand']\n",
    "\n",
    "# Resample to 15-minute intervals\n",
    "demand_data = demand_data.set_index('timestamp').resample('15T').sum().reset_index()\n",
    "\n",
    "# Feature selection\n",
    "demand_data['hour'] = demand_data['timestamp'].dt.hour\n",
    "demand_data['minute'] = demand_data['timestamp'].dt.minute\n",
    "X = demand_data[['hour', 'minute']]\n",
    "y = demand_data['demand']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Linear Regression model\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# XGBoost model\n",
    "model_xgb = XGBRegressor()\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "# ARIMA model\n",
    "model_arima = ARIMA(y_train, order=(5, 1, 0))\n",
    "model_arima_fit = model_arima.fit()\n",
    "\n",
    "# Deep Neural Network model\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model_dnn = MLPRegressor(hidden_layer_sizes=(100,), max_iter=500)\n",
    "model_dnn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Random Forest model\n",
    "model_rf = RandomForestRegressor()\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate models\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "mse_lr = evaluate_model(model_lr, X_test, y_test)\n",
    "mse_xgb = evaluate_model(model_xgb, X_test, y_test)\n",
    "mse_arima = mean_squared_error(y_test, model_arima_fit.forecast(steps=len(X_test)))\n",
    "mse_dnn = evaluate_model(model_dnn, X_test_scaled, y_test)\n",
    "mse_rf = evaluate_model(model_rf, X_test, y_test)\n",
    "\n",
    "# Compare model performances\n",
    "print(f'Mean Squared Error - Linear Regression: {mse_lr}')\n",
    "print(f'Mean Squared Error - XGBoost: {mse_xgb}')\n",
    "print(f'Mean Squared Error - ARIMA: {mse_arima}')\n",
    "print(f'Mean Squared Error - Deep Neural Network: {mse_dnn}')\n",
    "print(f'Mean Squared Error - Random Forest: {mse_rf}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a657a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Predictions:\n",
      "       start_datetime  prediction_xgb  prediction_lr  prediction_arima  \\\n",
      "0 2022-04-01 08:00:00        1.695130       0.332314               NaN   \n",
      "1 2022-04-01 12:30:00        0.225307       1.687168               NaN   \n",
      "\n",
      "   prediction_dnn  prediction_rf  \n",
      "0        1.804121       1.703766  \n",
      "1        0.092288       0.226951  \n"
     ]
    }
   ],
   "source": [
    "# Sample dataset for prediction\n",
    "sample_data = pd.DataFrame({\n",
    "    'start_date': ['04-01-2022', '04-01-2022'],\n",
    "    'start_time_hour': [8, 12],\n",
    "    'start_time_minute': [0, 30],\n",
    "})\n",
    "\n",
    "# Feature engineering for the sample dataset\n",
    "sample_data['start_datetime'] = pd.to_datetime(sample_data['start_date'] + ' ' + sample_data['start_time_hour'].astype(str) + ':' + sample_data['start_time_minute'].astype(str))\n",
    "sample_data['hour'] = sample_data['start_datetime'].dt.hour\n",
    "sample_data['minute'] = sample_data['start_datetime'].dt.minute\n",
    "\n",
    "# Select relevant features\n",
    "sample_features = sample_data[['hour', 'minute']]\n",
    "\n",
    "# Predict using the trained XGBoost model\n",
    "sample_prediction_xgb = model_xgb.predict(sample_features)\n",
    "\n",
    "# Predict using the trained Linear Regression model\n",
    "sample_prediction_lr = model_lr.predict(sample_features)\n",
    "\n",
    "# Predict using the trained ARIMA model\n",
    "sample_prediction_arima = model_arima_fit.forecast(steps=len(sample_features))\n",
    "\n",
    "# Predict using the trained Deep Neural Network model\n",
    "sample_features_scaled = scaler.transform(sample_features)\n",
    "sample_prediction_dnn = model_dnn.predict(sample_features_scaled)\n",
    "\n",
    "# Predict using the trained Random Forest model\n",
    "sample_prediction_rf = model_rf.predict(sample_features)\n",
    "\n",
    "# Display the predictions\n",
    "sample_data['prediction_xgb'] = sample_prediction_xgb\n",
    "sample_data['prediction_lr'] = sample_prediction_lr\n",
    "sample_data['prediction_arima'] = sample_prediction_arima\n",
    "sample_data['prediction_dnn'] = sample_prediction_dnn\n",
    "sample_data['prediction_rf'] = sample_prediction_rf\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "print(sample_data[['start_datetime', 'prediction_xgb', 'prediction_lr', 'prediction_arima', 'prediction_dnn', 'prediction_rf']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2301182a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
